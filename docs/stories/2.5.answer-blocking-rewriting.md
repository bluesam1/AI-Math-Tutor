# Story 2.5: Answer Blocking & Response Rewriting

## Status

Pending

## Story

**As a** student,
**I want** the system to rewrite or block responses that contain direct answers,
**so that** I never receive direct answers even if the guardrails detect them.

## Acceptance Criteria

1: A backend service module combines keyword-based detection and LLM-based validation to determine if a response contains direct answers.

2: When a response is flagged for containing direct answers (by either detection method), the system:

- Blocks the response from being sent to the frontend
- Generates a replacement response that maintains Socratic principles (asks a guiding question instead)
- Logs the blocked response for monitoring and improvement

3: The replacement response is generated using the LLM service with a prompt instructing it to:

- Rewrite the response as a guiding question
- Maintain the same pedagogical intent without giving away the answer
- Use Socratic questioning techniques

4: The system handles cases where rewriting fails (e.g., LLM API error) by returning a generic Socratic question (e.g., "Let's think about this step by step. What do you think we should consider first?").

5: The blocking and rewriting logic is applied to all LLM-generated responses before they are returned to the frontend.

6: The system maintains 100% adherence to Socratic principles, never sending direct answers to the frontend.

7: The blocking and rewriting process is logged for monitoring and improvement, tracking detection rates and rewriting quality.

8: The system handles edge cases gracefully (e.g., responses that are borderline, ambiguous responses) by defaulting to blocking when uncertain.

## Tasks / Subtasks

- [ ] Task 1: Create Answer Blocking Service Module (AC: 1)
  - [ ] Create `functions/src/services/answerBlockingService.ts`
  - [ ] Define TypeScript interfaces for blocking results
  - [ ] Import keyword detection service (Story 2.3)
  - [ ] Import LLM validation service (Story 2.4)
  - [ ] Create service structure

- [ ] Task 2: Combine Detection Methods (AC: 1)
  - [ ] Implement `checkForAnswers()` function
  - [ ] Call keyword-based detection (Story 2.3)
  - [ ] Call LLM-based validation (Story 2.4)
  - [ ] Combine detection results
  - [ ] Determine if response should be blocked (either method flags it)

- [ ] Task 3: Implement Response Blocking (AC: 2)
  - [ ] Create `blockResponse()` function
  - [ ] Flag response for blocking when answer detected
  - [ ] Prevent response from being sent to frontend
  - [ ] Return blocking result with flag

- [ ] Task 4: Create Rewriting Prompt Template (AC: 3)
  - [ ] Design prompt template for response rewriting
  - [ ] Include instructions to rewrite as guiding question
  - [ ] Include instructions to maintain pedagogical intent
  - [ ] Include instructions to use Socratic questioning
  - [ ] Include original response to rewrite
  - [ ] Include problem context

- [ ] Task 5: Implement Response Rewriting (AC: 2, 3)
  - [ ] Create `rewriteResponse()` function
  - [ ] Use LLM service from Story 2.1
  - [ ] Build rewriting prompt with original response
  - [ ] Call LLM API to generate rewritten response
  - [ ] Return rewritten response
  - [ ] Ensure rewritten response maintains Socratic principles

- [ ] Task 6: Implement Fallback Socratic Question (AC: 4)
  - [ ] Create library of generic Socratic questions
  - [ ] Select appropriate generic question when rewriting fails
  - [ ] Examples: "Let's think about this step by step. What do you think we should consider first?"
  - [ ] Ensure fallback questions are always safe (never contain answers)

- [ ] Task 7: Handle Rewriting Failures (AC: 4)
  - [ ] Detect rewriting failures (LLM API errors, timeouts, etc.)
  - [ ] Fall back to generic Socratic question when rewriting fails
  - [ ] Log rewriting failures for monitoring
  - [ ] Ensure system never sends blocked response even if rewriting fails

- [ ] Task 8: Integrate with Dialogue Endpoint (AC: 5)
  - [ ] Integrate blocking service into chat endpoint (Story 2.2)
  - [ ] Apply blocking/rewriting to all LLM-generated responses
  - [ ] Ensure blocking happens before response is sent to frontend
  - [ ] Return rewritten response instead of original

- [ ] Task 9: Implement Logging (AC: 2, 7)
  - [ ] Log all blocked responses
  - [ ] Log detection method that flagged response (keyword, LLM, or both)
  - [ ] Log original response and rewritten response
  - [ ] Track detection rates (how often answers are detected)
  - [ ] Track rewriting quality
  - [ ] Create monitoring dashboard or logs

- [ ] Task 10: Handle Edge Cases (AC: 8)
  - [ ] Handle borderline responses (uncertain if answer present)
  - [ ] Default to blocking when uncertain
  - [ ] Handle ambiguous responses
  - [ ] Handle very short responses
  - [ ] Handle responses that are mostly questions but contain answers

- [ ] Task 11: Ensure 100% Adherence (AC: 6)
  - [ ] Verify all code paths maintain Socratic principles
  - [ ] Test that blocked responses are never sent to frontend
  - [ ] Test that rewritten responses don't contain answers
  - [ ] Test fallback questions don't contain answers
  - [ ] Add safeguards to prevent accidental answer leakage

- [ ] Task 12: Add Unit Tests (AC: 1-8)
  - [ ] Create test file `functions/src/services/__tests__/answerBlockingService.test.ts`
  - [ ] Test detection method combination
  - [ ] Test response blocking logic
  - [ ] Test response rewriting
  - [ ] Test fallback handling
  - [ ] Test edge cases
  - [ ] Mock detection services and LLM service

- [ ] Task 13: Integration Testing (AC: 1-8)
  - [ ] Test with real LLM responses that contain answers
  - [ ] Test with responses that don't contain answers
  - [ ] Test rewriting quality
  - [ ] Test fallback scenarios
  - [ ] Verify 100% adherence to Socratic principles
  - [ ] Test across different problem types

- [ ] Task 14: Monitoring and Improvement (AC: 7)
  - [ ] Set up logging infrastructure
  - [ ] Create metrics for detection rates
  - [ ] Create metrics for rewriting quality
  - [ ] Review blocked responses regularly
  - [ ] Improve detection patterns based on findings

## Dependencies

- Story 2.1: LLM Integration Backend Service (for rewriting)
- Story 2.3: Keyword-Based Answer Detection Guardrail
- Story 2.4: LLM-Based Answer Detection Guardrail

## Required By

- Story 2.7: Chat UI Component (consumes responses that have been checked/rewritten)

## Notes

- This is the critical guardrail that ensures no answers ever reach the frontend
- Must maintain 100% adherence - better to be overly cautious than allow answers through
- Rewriting should preserve pedagogical intent while removing answers
- Logging is crucial for monitoring and improving detection patterns
- Consider cost implications of rewriting (additional LLM call per blocked response)

